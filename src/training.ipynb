{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing opencv haarcascade face detection network\n",
    "https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "explained in: https://www.youtube.com/watch?v=7IFhsbfby9s&t=300s (or gitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImg(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def faceNetLocalize(img, **kwargs):\n",
    "    scaleFactor = kwargs.get('scaleFactor', 1.1) #between 1.05 (quality) and 1.4 (speed) recommended (scale of the faces we search for)\n",
    "    minNeighbors = kwargs.get('minNeighbors', 4) #between 3 (quantity) and 6 (quality) recommended\n",
    "    minSize = kwargs.get('minSize', (10, 10)) #min size of a face in the picture\n",
    "    faceNet = kwargs.get('faceNet', init_faceNet())\n",
    "    \n",
    "    img_cvt = convertImg(img)\n",
    "    return faceNet.detectMultiScale3(img_cvt, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize, outputRejectLevels = True)\n",
    "\n",
    "def init_faceNet(**kwargs):\n",
    "    path = kwargs.get('path', 'haarcascade_frontalface_default.xml')\n",
    "    return cv2.CascadeClassifier(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: testing with different model types\n",
    "#for example: eye model + larger bounding box towards the bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask classifier\n",
    "\n",
    "foundation: https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import MaxPool2D, Conv2D, Input, Dense, Flatten, AveragePooling2D, Dropout\n",
    "import tensorflow.keras.layers as lays\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomContrast, RandomFlip, RandomRotation\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential, losses as lfs\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = Sequential([\n",
    "  RandomFlip(\"horizontal\"),\n",
    "  RandomRotation(0.4),\n",
    "  RandomContrast(0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = (180, 180)\n",
    "img_size_vgg = (224, 224)\n",
    "epochs = 11\n",
    "checkpoint_path = \"mask_model/weights.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "imgs_path = os.path.join('..', 'img')\n",
    "num_classes = 3\n",
    "\n",
    "correct_usage =  'correct usage: \\n' + 'predict([path to image], \\'category\\' \\n' + 'predict([path to image], \\'probabilities\\' \\n' + 'predict([path to image], \\'detection\\' \\n' + 'predict(\\'live_detection\\')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(**kwargs):\n",
    "    imgs_path = kwargs.get('imgs_path', os.path.join('..', 'img'))\n",
    "    img_size = kwargs.get('img_size', (180, 180))\n",
    "    batch_size = kwargs.get('batch_size', 32)\n",
    "\n",
    "    ##load images/ labels from directory\n",
    "    valid_images = [\".jpg\",\".png\",\".jpeg\",\".JPG\"]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    \n",
    "    for root, dirs, files in os.walk(imgs_path):\n",
    "        for filename in files:\n",
    "            end = os.path.splitext(filename)[1]\n",
    "            if end.lower() not in valid_images:\n",
    "                continue\n",
    "            image = load_img(os.path.join(root, filename), target_size=img_size)\n",
    "            image = img_to_array(image)\n",
    "            \n",
    "            label = os.path.join(root, filename).split(os.path.sep)[-2]\n",
    "            \n",
    "            x.append(image)\n",
    "            y.append(label)\n",
    "    x = np.array(x, dtype=\"float32\")\n",
    "    y = np.array(y)\n",
    "\n",
    "    ## convert labels to ints from 0 ... len(labels)-1\n",
    "    labels = []\n",
    "    for i in range(len(y)):\n",
    "        try:\n",
    "            j = labels.index(y[i])\n",
    "        except:\n",
    "            labels.append(y[i])\n",
    "            j = labels.index(y[i])\n",
    "        y[i] = j\n",
    "    y.astype(int)\n",
    "    \n",
    "    ## split dataset\n",
    "    trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.2, random_state=3)\n",
    "\n",
    "    ## one-hot encoding\n",
    "    trainY = utils.to_categorical(trainY, num_classes)\n",
    "    testY = utils.to_categorical(testY, num_classes)\n",
    "\n",
    "    ## data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    ## merge xs and ys\n",
    "    train_batches = datagen.flow(trainX, trainY, batch_size=32, subset='training')\n",
    "    test_batches  = datagen.flow(trainX, trainY, batch_size=32, subset='validation')\n",
    "    \n",
    "    return train_batches, test_batches, labels, testX, testY, trainX, trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypermodels\n",
    "#https://www.analyticsvidhya.com/blog/2021/06/create-convolutional-neural-network-model-and-optimize-using-keras-tuner-deep-learning/\n",
    "#https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "\n",
    "def basic_model_builder(hp):\n",
    "  \n",
    "    basic_model = Sequential([\n",
    "        Rescaling(1. /255),\n",
    "        augmentation,\n",
    "        Conv2D(filters=hp.Int('c1_filter', min_value=32, max_value=256, step=16), kernel_size=hp.Choice('c1_kernel', values=[3,5]), activation='relu'),\n",
    "        AveragePooling2D(pool_size=(7,7)),\n",
    "        Flatten(name=\"flatten\"),\n",
    "        Dense(units=hp.Int('d1_units', min_value=32, max_value=512, step=32), activation=\"relu\"),\n",
    "        Dropout(0.2),#drops small confidences\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    basic_model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), loss=lfs.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    return basic_model\n",
    "\n",
    "def small_model_builder(hp):\n",
    "  \n",
    "    small_model = Sequential([\n",
    "        Rescaling(1. /255),\n",
    "        augmentation,\n",
    "        Conv2D(filters=hp.Int('c1_filter', min_value=32, max_value=256, step=16), kernel_size=hp.Choice('c1_kernel', values=[3,5]), activation='relu'),\n",
    "        Conv2D(filters=hp.Int('c2_filter', min_value=32, max_value=256, step=16), kernel_size=hp.Choice('c2_kernel', values=[3,5]), activation='relu'),\n",
    "        MaxPool2D(pool_size=(3,3)),\n",
    "        Flatten(name=\"flatten\"),\n",
    "        Dense(units=hp.Int('d1_units', min_value=32, max_value=512, step=32), activation=\"relu\"),\n",
    "        Dropout(0.2),#drops small confidences\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    small_model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), loss=lfs.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    return small_model\n",
    "\n",
    "\n",
    "def tune_model(model_builder, xs, ys):\n",
    "    #tuner = kt.RandomSearch(model_builder, objective='val_accuracy', max_trials=5)\n",
    "    tuner = kt.RandomSearch(kt.applications.HyperResNet(input_shape=(180, 180, 3), classes=2), objective='val_loss', max_trials=5)\n",
    "    tuner = kt.Hyperband(model_builder, objective='val_accuracy', max_epochs=10, factor=3)\n",
    "    tuner.search(xs, ys, epochs=50, validation_split=0.2)\n",
    "    return tuner.get_best_hyperparameters(num_trials=1)[0], tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_name, **kwargs):\n",
    "    num_labels = kwargs.get('num_classes', num_classes)\n",
    "\n",
    "    basic_model = Sequential([ \n",
    "    Rescaling(1. /255),\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(180,180,3)),\n",
    "    AveragePooling2D(pool_size=(7,7)),\n",
    "    Flatten(name=\"flatten\"),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),#drops small confidences\n",
    "    Dense(num_labels, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    small_model = Sequential([ \n",
    "        Rescaling(1. /255),\n",
    "        Conv2D(filters=128, kernel_size=(5,5), activation='relu', input_shape=(180,180,3)),\n",
    "        Conv2D(filters=128, kernel_size=(5,5), activation='relu'),\n",
    "        MaxPool2D(pool_size=(3,3)),\n",
    "        Flatten(name=\"flatten\"),\n",
    "        Dense(units=224, activation=\"relu\"),\n",
    "        Dropout(0.5),#drops small confidences\n",
    "        Dense(num_labels, activation=\"softmax\")\n",
    "        ])\n",
    "\n",
    "    vgg_small_model=Sequential()\n",
    "\n",
    "    vgg_small_model.add(Conv2D(64,(3,3),activation='relu',input_shape=(180,180,3)))\n",
    "    vgg_small_model.add(MaxPool2D(2,2))\n",
    "    vgg_small_model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "    vgg_small_model.add(MaxPool2D(2,2))\n",
    "    vgg_small_model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "    vgg_small_model.add(MaxPool2D(2,2))\n",
    "    vgg_small_model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "    vgg_small_model.add(MaxPool2D(2,2))\n",
    "    vgg_small_model.add(Flatten())\n",
    "    vgg_small_model.add(Dropout(0.5))\n",
    "    vgg_small_model.add(Dense(120,activation='relu'))\n",
    "    vgg_small_model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "    vgg_model = Sequential([\n",
    "        Rescaling(1. /255),\n",
    "        Conv2D(input_shape=(224,224,3), filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", strides=(1,1)), \n",
    "        Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2)),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2)),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2)),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2)),\n",
    "        Flatten(),\n",
    "        Dense(units=4096, activation=\"relu\"),\n",
    "        Dense(units=4096, activation=\"relu\"),\n",
    "        Dense(units=num_labels, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    if model_name == 'basic_model':\n",
    "        return basic_model\n",
    "    \n",
    "    if model_name == 'small_model':\n",
    "        return small_model\n",
    "\n",
    "    if model_name == 'vgg_model':\n",
    "        return vgg_model\n",
    "    \n",
    "    if model_name == 'vgg_small_model':\n",
    "        return vgg_small_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about the VGG-model: https://neurohive.io/en/popular-networks/vgg16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_ds, val_ds, **kwargs):\n",
    "    epochs = kwargs.get('epochs', 10)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing/Evaluation (mask):\n",
    "https://www.tensorflow.org/guide/keras/train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x_test, y_test, model):\n",
    "    results = model.evaluate(x_test, y_test, batch_size=32)\n",
    "    print(results)\n",
    "    \n",
    "    y_pred_confidences = model.predict(x_test)\n",
    "    y_pred = [np.argmax(cs) for cs in y_pred_confidences]\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(**kwargs):\n",
    "    checkpoint_path = kwargs.get('checkpoint_path', \"mask_model/weights.ckpt\")\n",
    "    model = kwargs.get('model', select_model('basic_model'))\n",
    "    model.load_weights(checkpoint_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskPredict(img, labels):\n",
    "    pred = model.predict(img[None])\n",
    "    label_index = np.argmax(pred)\n",
    "    return labels[label_index], pred[0][label_index]\n",
    "\n",
    "\n",
    "#mode can be 'category', 'probabilities', 'detection', 'live_detection'\n",
    "def predict(mode, **kwargs):\n",
    "    img_path = kwargs.get('img_path', None)\n",
    "    model = kwargs.get('model', load_model())\n",
    "    if mode=='live_detection':\n",
    "        live_det()\n",
    "        return\n",
    "    \n",
    "    if img_path is None:\n",
    "        print(correct_usage)\n",
    "        return\n",
    "\n",
    "    #load_img\n",
    "    img = load_img(img_path, target_size = img_size)\n",
    "    img = img_to_array(img)\n",
    "    \n",
    "    if mode=='detection':\n",
    "        detect(img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "        \n",
    "    if mode=='category':\n",
    "        label, confidence = maskPredict(img)\n",
    "        return label\n",
    "        \n",
    "    if mode=='probabilities':\n",
    "        #TODO: sch√∂neres Format\n",
    "        return model.predict(img[None])\n",
    "\n",
    "    else:\n",
    "        print(correct_usage)\n",
    "\n",
    "def detect(img):\n",
    "    faceLocs, rejectLevels, confidences = faceNetLocalize(img)\n",
    "        \n",
    "    for (x, y, w, h) in faceLocs:\n",
    "        #crop image and predict label of cropped image\n",
    "        img_crop = img[y:y+h, x:x+w]\n",
    "        label, confidence_mask = maskPredict(img)\n",
    "        #show label/ bounding box on image\n",
    "        cv2.putText(img, f\"{label}, confidence:{confidence_mask}\", (x+w-30, y+h), cv2.FONT_HERSHEY_PLAIN, 1.0, cv2.CV_RGB(0,255,0), 2.0) \n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('live_output', img)\n",
    "\n",
    "def live_det():\n",
    "    #TODO: errorhandling for camera\n",
    "    \n",
    "    wait_time = 10 #time in ms to wait before refreshing feed\n",
    "    camera = cv2.VideoCapture(0) #Input value might differ on different systems\n",
    "    \n",
    "    while(True):\n",
    "        _, img = camera.read()\n",
    "\n",
    "        detect(img)\n",
    "\n",
    "        #wait for ESC or q\n",
    "        if (cv2.waitKey(wait_time) & 0xFF) in [27, ord('q')]: \n",
    "            break\n",
    "\n",
    "    camera.release()\n",
    "    return 'live_output'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds, labels, testX, testY, trainX, trainY = load_dataset()\n",
    "#bhps, tuner = tune_model(basic_model_builder, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julie\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Julie\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 24.7669 - accuracy: 0.3633 - val_loss: 1.4504 - val_accuracy: 0.2787\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.2100 - accuracy: 0.4204 - val_loss: 1.1712 - val_accuracy: 0.3934\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 1.0612 - accuracy: 0.4612 - val_loss: 0.8167 - val_accuracy: 0.6721\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.7761 - accuracy: 0.6816 - val_loss: 0.6202 - val_accuracy: 0.7541\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.5632 - accuracy: 0.7592 - val_loss: 0.4734 - val_accuracy: 0.8033\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.4632 - accuracy: 0.7837 - val_loss: 0.4139 - val_accuracy: 0.8361\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4409 - accuracy: 0.8245 - val_loss: 0.3495 - val_accuracy: 0.9016\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.5433 - accuracy: 0.8082 - val_loss: 1.2452 - val_accuracy: 0.5246\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.6870 - accuracy: 0.7224 - val_loss: 0.3204 - val_accuracy: 0.9016\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3998 - accuracy: 0.8776 - val_loss: 0.3044 - val_accuracy: 0.9016\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.6247 - accuracy: 0.7755 - val_loss: 0.3859 - val_accuracy: 0.9016\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.3935 - accuracy: 0.8571 - val_loss: 0.2419 - val_accuracy: 0.9508\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.3186 - accuracy: 0.8694 - val_loss: 0.2439 - val_accuracy: 0.9344\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.2931 - accuracy: 0.8776 - val_loss: 0.2704 - val_accuracy: 0.8852\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3184 - accuracy: 0.8735 - val_loss: 0.5636 - val_accuracy: 0.8033\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.4997 - accuracy: 0.8312\n",
      "[0.4997439682483673, 0.8311688303947449]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3290658191.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#model = tuner.hypermodel.build(bhps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/960432350.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(x_test, y_test, model)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_pred_confidences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred_confidences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     \"\"\"\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2076\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "model = select_model('vgg_small_model')\n",
    "#model = tuner.hypermodel.build(bhps)\n",
    "history = train_model(model, train_ds, test_ds, epochs=15)\n",
    "evaluate_model(testX, testY, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path='../img/ffp2/IMG_1596_(657, 421, 1426, 1426).png'\n",
    "#img_path='../img/no_mask/IMG_1323.JPG_(1025, 427, 984, 984).png'\n",
    "#img_path='../img/op_mask/IMG_1337.JPG_(878, 710, 954, 954).png'\n",
    "#img_path='../img/other_mask/IMG_1327.JPG_(863, 476, 1097, 1097).png'\n",
    "\n",
    "#predict(img_path, 'category', model=model, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "320b063615c881cf99d5bda0a05a87a093cceae5b3aed84278fa7ef3d4b95f2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
