{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib. pyplot as plt\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "#preprocessing required\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2',\n",
       "       'ffp2', 'ffp2', 'ffp2', 'ffp2', 'ffp2', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask', 'no_mask',\n",
       "       'no_mask', 'no_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask', 'op_mask',\n",
       "       'op_mask', 'op_mask', 'op_mask', 'op_mask'], dtype='<U7')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_path = os.path.join('..', 'img')\n",
    "img_size = (150, 150)\n",
    "\n",
    "valid_images = [\".jpg\",\".png\",\".jpeg\",\".JPG\"]\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for root, dirs, files in os.walk(imgs_path):\n",
    "    for filename in files:\n",
    "        end = os.path.splitext(filename)[1]\n",
    "        if end.lower() not in valid_images:\n",
    "            continue\n",
    "        image = load_img(os.path.join(root, filename), target_size=img_size)\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        label = os.path.join(root, filename).split(os.path.sep)[-2]\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ffp2', 'no_mask', 'op_mask']\n"
     ]
    }
   ],
   "source": [
    "# labels text to index\n",
    "label_str = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    try:\n",
    "        j = label_str.index(labels[i])\n",
    "    except:\n",
    "        label_str.append(labels[i])\n",
    "        j = label_str.index(labels[i])\n",
    "    labels[i] = j\n",
    "\n",
    "labels.astype(int)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27121/3385902016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m datagen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfeaturewise_center\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeaturewise_std_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrotation_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwidth_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "trainY = utils.to_categorical(trainY, num_classes)\n",
    "testY = utils.to_categorical(testY, num_classes)\n",
    "\n",
    "train_batches = datagen.flow(trainX, trainY, batch_size=32,\n",
    "         subset='training')\n",
    "\n",
    "test_batches = datagen.flow(trainX, trainY,\n",
    "         batch_size=32, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path='Mask_Datasets\\Train'\n",
    "test_path='Mask_Datasets\\Validation'\n",
    "\n",
    "\n",
    "train_batches=ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_path,\n",
    "        color_mode='grayscale',\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        classes=label_str)\n",
    "            \n",
    "test_batches=ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale',\n",
    "        classes=label_str)            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 120)               752760    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 363       \n",
      "=================================================================\n",
      "Total params: 1,013,283\n",
      "Trainable params: 1,013,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "width,height=150,150\n",
    "num_features=64\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features,(3,3),activation='relu',input_shape=(width,height,3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(num_features,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(2*num_features,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(2*num_features,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzirus/miniconda3/lib/python3.9/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/lzirus/miniconda3/lib/python3.9/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 15s 1s/step - loss: 26.8738 - accuracy: 0.2894 - val_loss: 1.1501 - val_accuracy: 0.4516\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.3664 - accuracy: 0.3410 - val_loss: 0.9587 - val_accuracy: 0.5161\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.9654 - accuracy: 0.5486 - val_loss: 0.6998 - val_accuracy: 0.6613\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.7457 - accuracy: 0.6429 - val_loss: 0.6758 - val_accuracy: 0.6935\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.6893 - accuracy: 0.6973 - val_loss: 0.6407 - val_accuracy: 0.6774\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.5940 - accuracy: 0.6951 - val_loss: 0.5184 - val_accuracy: 0.7581\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.5687 - accuracy: 0.7413 - val_loss: 0.5644 - val_accuracy: 0.7097\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4473 - accuracy: 0.8047 - val_loss: 0.5009 - val_accuracy: 0.7903\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.4654 - accuracy: 0.7999 - val_loss: 0.7391 - val_accuracy: 0.6774\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 8s 963ms/step - loss: 0.5640 - accuracy: 0.7684 - val_loss: 0.6405 - val_accuracy: 0.7097\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4226 - accuracy: 0.8390 - val_loss: 0.5219 - val_accuracy: 0.8226\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 8s 935ms/step - loss: 0.4561 - accuracy: 0.8314 - val_loss: 0.3512 - val_accuracy: 0.8548\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 8s 956ms/step - loss: 0.4020 - accuracy: 0.8380 - val_loss: 0.3203 - val_accuracy: 0.8548\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3507 - accuracy: 0.8576 - val_loss: 0.3076 - val_accuracy: 0.8871\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 8s 943ms/step - loss: 0.3402 - accuracy: 0.8598 - val_loss: 0.3760 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_batches,epochs=15,\n",
    "                           validation_data=test_batches,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('mask_three.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('mask.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_batches[0][0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzirus/miniconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
      "/home/lzirus/miniconda3/lib/python3.9/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/lzirus/miniconda3/lib/python3.9/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/28 [=====>........................] - ETA: 5sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 28 batches). You may need to use the repeat() function when building your dataset.\n",
      "28/28 [==============================] - 2s 48ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 46]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25267/1456010857.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \"\"\"\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2076\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 46]"
     ]
    }
   ],
   "source": [
    "predictions=model.predict_generator(test_batches, steps=28, verbose=1)\n",
    "print(classification_report(test_batches[1], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'tensorflow.python.keras.preprocessing.image.NumpyArrayIterator'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25267/4029275566.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1355\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    959\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'tensorflow.python.keras.preprocessing.image.NumpyArrayIterator'>"
     ]
    }
   ],
   "source": [
    "model.evaluate(pred,test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 485ms/step - loss: 0.1090 - accuracy: 0.9492\n",
      "[0.10898660868406296, 0.9491525292396545]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(testX, testY)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25267/2051683482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrue_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrue_categories_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25267/2051683482.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrue_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrue_categories_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(val_ds)\n",
    "predicted_categories = np.argmax(y_pred, axis=1)\n",
    "\n",
    "true_categories = tensorflow.concat([y for x, y in testX], axis=0).numpy()\n",
    "true_categories_argmax = np.argmax(true_categories, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
